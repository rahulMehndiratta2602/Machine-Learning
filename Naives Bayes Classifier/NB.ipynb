{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I loaded the given data into a df - df_original by seperating the comments/messages from the corresponding labels. Then , I created two dataframes, df_raw which contained all the training data and df_test which contained all the testing data. df_positive contains all the data pertaining to the positive reviews and df_negative contains all the data of the negative reviews. The working of the functions used can be found in their docstrings. I create a 2 dictionaries, dict_positive and dict_negative - each having the number of occurences of unique positive and unique negative words from their respective comments. ie. each key in, say dict_positive is a unique word contained in the positive comments and its value is the number of times it appeared in the positive comments. \n",
    "Then, I use laplace smoothening and find out the probability that a word can be observed, given that it belongs to a particular category. And to find out the probability that a list of words belong to a particular category, i multiply the individual probabilities, assuming they are independent of each other. Then, I calculate the probability that a list of words belongs to a particular category, using the bayes theorem, then based on which probability is higher, i categorize an example as either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def find_words(stop_words,df_raw,df_positive,df_negative):\n",
    "    '''\n",
    "    Takes in the list of stop words and the raw data frame, positive\n",
    "    dataframe and a negative data frame and returns \n",
    "    three items as a list - set of all words, set of all words in the \n",
    "    positive reviews and a set of all words in the negative reviews.\n",
    "    '''\n",
    "    word_pattern = '[a-zA-Z\\']+'\n",
    "    total_words = set({})\n",
    "    positive_words = set({})\n",
    "    negative_words = set({})\n",
    "    for line in df_raw['comments']:\n",
    "        for i in re.finditer(word_pattern,line):\n",
    "            word = i.group().lower()\n",
    "            if (word not in stop_words and re.search('\\'',word)):\n",
    "                word = word.replace(\"'\",\"\")\n",
    "                total_words.add(word)\n",
    "            elif (word not in stop_words):\n",
    "                total_words.add(word)\n",
    "    for line in df_positive['comments']:\n",
    "        for i in re.finditer(word_pattern,line):\n",
    "            word = i.group().lower()\n",
    "            if (word not in stop_words and re.search('\\'',word)):\n",
    "                word = word.replace(\"'\",\"\")\n",
    "                positive_words.add(word)\n",
    "            elif (word not in stop_words):\n",
    "                positive_words.add(word)\n",
    "    for line in df_negative['comments']:\n",
    "        for i in re.finditer(word_pattern,line):\n",
    "            word = i.group().lower()\n",
    "            if (word not in stop_words and re.search('\\'',word)):\n",
    "                word = word.replace(\"'\",\"\")\n",
    "                negative_words.add(word)\n",
    "            elif (word not in stop_words):\n",
    "                negative_words.add(word)\n",
    "    return [total_words,positive_words,negative_words]\n",
    "\n",
    "def segregate(label):\n",
    "    '''\n",
    "    Will be used in the groupby function to segregate the dataframe into df_positive and df_negative.\n",
    "    '''\n",
    "    if (label == '1'):\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "    \n",
    "def word_counts(stop_words,df_raw,df_positive,df_negative):\n",
    "    '''\n",
    "    Takes in three dataframes - the raw df, a positive df and \n",
    "    a negative df and the stop_words and returns a list of 2 dictionaries - \n",
    "    one for positive and the other for negative reviews each having the \n",
    "    number of occurences of each unique word in the respective comments.\n",
    "    '''\n",
    "    total_words,positive_words,negative_words = find_words(stop_words,df_raw,df_positive,df_negative)\n",
    "    dict_positive = {word:0 for word in total_words}\n",
    "    dict_negative = {word:0 for word in total_words}\n",
    "    for line in df_positive['comments']:\n",
    "        for i in re.finditer('[a-zA-Z\\']+',line):\n",
    "            word = i.group().lower()\n",
    "            if (re.search('\\'',word)):\n",
    "                word = word.replace(\"'\",\"\")\n",
    "            if (word in dict_positive):\n",
    "                dict_positive[word] += 1\n",
    "               \n",
    "    for line in df_negative['comments']:\n",
    "        for i in re.finditer('[a-zA-Z\\']+',line):\n",
    "            word = i.group().lower()\n",
    "            if (re.search('\\'',word)):\n",
    "                word = word.replace(\"'\",\"\")\n",
    "            if (word in dict_negative):\n",
    "                dict_negative[word] += 1\n",
    "               \n",
    "    return [dict_positive,dict_negative]\n",
    "\n",
    "def prob_positive(words,dict_positive,alpha):\n",
    "    '''\n",
    "    Takes in a list of words, a dict containing the number of occurences of each positive word in the positive comments and\n",
    "    the value of alpha - the probabilities are calculated after laplace smoothening. Returns the probability that the words form \n",
    "    a positive comment.\n",
    "    '''\n",
    "    prob = 1\n",
    "    prob *= num_positive/(num_negative + num_positive)\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in dict_positive:\n",
    "            num = dict_positive[words[i]]\n",
    "        else:\n",
    "            num = 0\n",
    "        prob *= (num + alpha)/(alpha*total_num_unique_words + num_positive_words)\n",
    "    return prob\n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "def prob_negative(words,dict_negative,alpha):\n",
    "    '''\n",
    "    Takes in a list of words, a dict containing the number of occurences of each negative word in the negative comments and\n",
    "    the value of alpha - the probabilities are calculated after laplace smoothening. Returns the probability that the words form \n",
    "    a negative comment.\n",
    "    '''\n",
    "    prob = 1\n",
    "    prob *= num_negative/(num_negative + num_positive)\n",
    "    for i in range(len(words)):\n",
    "        if (words[i] in dict_negative):\n",
    "            num = dict_negative[words[i]]\n",
    "        else:\n",
    "            num = 0\n",
    "        prob *= (num + alpha)/(alpha*total_num_unique_words + num_negative_words)\n",
    "    return prob\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "def predict(string,dict_positive,dict_negative,alpha):\n",
    "    '''\n",
    "    Takes in a string, dict_positive, dict_negative, alpha and returns 1 if the comment is positive and 0 if the comment is \n",
    "    negative.\n",
    "    '''\n",
    "    words = []\n",
    "    pattern = '[a-zA-Z\\']+'\n",
    "    for i in re.finditer(pattern,string):\n",
    "        word = i.group().lower()\n",
    "        if (word not in stop_words):\n",
    "            if (re.search(\"'\",word)):\n",
    "                word = word.replace(\"'\",\"\")\n",
    "        words.append(word)\n",
    "    i = len(words)\n",
    "    pos_prob = prob_positive(words,dict_positive,alpha)\n",
    "    neg_prob = prob_negative(words,dict_negative,alpha)\n",
    "    if (pos_prob >= neg_prob):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def accuracy(df_test):\n",
    "    '''\n",
    "    Returns the accuracy of the test dataframe.\n",
    "    '''\n",
    "    a = []\n",
    "    for string in df_test['comments']:\n",
    "        a.append(predict(string,dict_positive,dict_negative,1))\n",
    "    count = 0\n",
    "    for y_pred,y in zip(a,df_test['labels']):\n",
    "        if y_pred == int(y):\n",
    "            count += 1\n",
    "    total = len(df_test)\n",
    "    accuracy = count/total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stop_words = ['a','the','an','be']\n",
    "with open('dataset_NB.txt','r') as dataset:\n",
    "    file_reader = dataset.read()\n",
    "pattern = '(?P<comments>.*)\\..*(?P<label>\\d)\\\\n'\n",
    "comment = []\n",
    "labels = []\n",
    "for item in re.finditer(pattern,file_reader):\n",
    "    comment.append(item.groupdict()['comments'])\n",
    "    labels.append(item.groupdict()['label'])\n",
    "\n",
    "df_original = pd.DataFrame({'comments':comment,'labels':labels}, index = np.arange(1,len(labels)+1))\n",
    "\n",
    "accuracies_list = []\n",
    "length = int(len(df_original)/7)\n",
    "\n",
    "a = 0\n",
    "b = length\n",
    "\n",
    "for i in range(7):\n",
    "    df_one = df_original[:a].copy()\n",
    "    df_two = df_original[b:].copy()\n",
    "    df_raw = pd.concat([df_one,df_two])\n",
    "    df_test = df_original[a:b]\n",
    "    df_positive = None\n",
    "    df_negative = None\n",
    "    df_raw.set_index('labels',inplace = True)\n",
    "    for group,frame in df_raw.groupby(segregate):\n",
    "        if (group == 'positive'):\n",
    "            df_positive = frame\n",
    "        else:\n",
    "            df_negative = frame\n",
    "    df_positive.reset_index(inplace = True)\n",
    "    df_negative.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "    num_positive = len(df_positive)\n",
    "\n",
    "    num_negative = len(df_negative)\n",
    "\n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    "    for line in df_positive['comments']:\n",
    "        for i in re.finditer('[a-zA-Z\\']+',line):\n",
    "            word = i.group().lower()\n",
    "            if (word not in stop_words and re.search('\\'',word)):\n",
    "                word = word.replace(\"'\",\"\")\n",
    "                pos_words.append(word)\n",
    "            elif (word not in stop_words):\n",
    "                pos_words.append(word)\n",
    "    for line in df_negative['comments']:\n",
    "        for i in re.finditer('[a-zA-Z\\']+',line):\n",
    "            word = i.group().lower()\n",
    "            if (word not in stop_words and re.search('\\'',word)):\n",
    "                word = word.replace(\"'\",\"\")\n",
    "                neg_words.append(word)\n",
    "            elif (word not in stop_words):\n",
    "                neg_words.append(word)\n",
    "    num_positive_words = len(pos_words)\n",
    "    num_negative_words = len(neg_words)\n",
    "\n",
    "\n",
    "        \n",
    "    total_words,positive_words,negative_words = find_words(stop_words,df_raw,df_positive,df_negative)\n",
    "\n",
    "    total_num_unique_words = len(total_words)\n",
    "\n",
    "\n",
    "    dict_positive,dict_negative = word_counts(stop_words,df_raw,df_positive,df_negative)\n",
    "    \n",
    "    accuracies_list.append(accuracy(df_test))\n",
    "    \n",
    "    a += length\n",
    "    b += length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of model over each fold and the overall accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in fold 1 is 82.44274809160305\n",
      "Accuracy in fold 2 is 86.25954198473282\n",
      "Accuracy in fold 3 is 75.57251908396947\n",
      "Accuracy in fold 4 is 83.96946564885496\n",
      "Accuracy in fold 5 is 77.09923664122137\n",
      "Accuracy in fold 6 is 81.67938931297711\n",
      "Accuracy in fold 7 is 80.1526717557252\n",
      "\n",
      "Average accuracy across all folds is 0.8102508178844057\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    print('Accuracy in fold ' + str(i+1) + ' is ' + str(accuracies_list[i]*100))\n",
    "print()\n",
    "print('Average accuracy across all folds is ' + str(np.mean(accuracies_list*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major limitations of the Naive bayes classifier:\n",
    "\n",
    "1) Assumption that the feature parameters predict the probability independently of one another.\n",
    "2) The order of the words is ignored while implementing the algorithm.\n",
    "3) Without laplace smoothening, the presence of a word absent in the original dataset results in 0 probabilities for the whole sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
